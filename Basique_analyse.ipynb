{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "from generateWordFrequency import *\n",
    "from naiveBayes import *\n",
    "from fileWriteFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = getDataframe(2018)\n",
    "df_2018 = addTokenizedColumnofTitle(df_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Points</th>\n",
       "      <th>Author</th>\n",
       "      <th>tokenized_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Hacker News Books in 2017</td>\n",
       "      <td>story</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0x54MUR41</td>\n",
       "      <td>[top, hacker, news, book, in, 2017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing enjoys best winter air quality in five...</td>\n",
       "      <td>story</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>gpetukhov</td>\n",
       "      <td>[beijing, enjoy, best, winter, air, quality, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ask HN: Any domain name registrars that don't ...</td>\n",
       "      <td>ask_hn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>glockenspielen</td>\n",
       "      <td>[ask, hn, any, domain, name, registrars, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Controversial Therapy Has Led to Death Threats...</td>\n",
       "      <td>story</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>cpncrunch</td>\n",
       "      <td>[controversial, therapy, have, lead, to, death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...</td>\n",
       "      <td>story</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>geraldbauer</td>\n",
       "      <td>[ruby, 3x3, ruby, 3, will, be, 3, time, faster...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Post Type  \\\n",
       "0                      Top Hacker News Books in 2017     story   \n",
       "1  Beijing enjoys best winter air quality in five...     story   \n",
       "2  Ask HN: Any domain name registrars that don't ...    ask_hn   \n",
       "3  Controversial Therapy Has Led to Death Threats...     story   \n",
       "4  Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...     story   \n",
       "\n",
       "   Number of Comments  Points          Author  \\\n",
       "0                 0.0       1       0x54MUR41   \n",
       "1                 0.0       2       gpetukhov   \n",
       "2                 2.0       1  glockenspielen   \n",
       "3                 0.0       2       cpncrunch   \n",
       "4                 0.0       2     geraldbauer   \n",
       "\n",
       "                                     tokenized_title  \n",
       "0                [top, hacker, news, book, in, 2017]  \n",
       "1  [beijing, enjoy, best, winter, air, quality, i...  \n",
       "2  [ask, hn, any, domain, name, registrars, that,...  \n",
       "3  [controversial, therapy, have, lead, to, death...  \n",
       "4  [ruby, 3x3, ruby, 3, will, be, 3, time, faster...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ask HN: Any domain name registrars that don't require JavaScript?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018['Title'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClasses = list(np.unique(df_2018['Post Type']))\n",
    "AllClasses = ['story', 'ask_hn', 'show_hn', 'poll']\n",
    "delta = 0.5\n",
    "appendClassPrefix = 'prob_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating frequency of each word and given their conditional post type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2018 = getWordFrequencyDataframe(df_2018,AllClasses)\n",
    "totalNumberOfWords = getTotalWordCount(words_2018)\n",
    "words_2018 = obtainDataframeWithClassProbabilities(words_2018, AllClasses, delta, appendClassPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ask_hn': 0.04516194251591264, 'poll': 9.025889862481542e-05, 'show_hn': 0.036915889537549505, 'story': 0.917831909047913}\n"
     ]
    }
   ],
   "source": [
    "priorProbabilities = {}\n",
    "unique, counts = np.unique(df_2018['Post Type'], return_counts=True)\n",
    "for index in range(len(unique)):\n",
    "    priorProbabilities[unique[index]] = counts[index]/np.sum(counts)\n",
    "print(priorProbabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeModel(words_2018,'model-2018.txt',AllClasses,appendClassPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2018 = renameModelRows(words_2018, AllClasses, appendClassPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [words_2018, priorProbabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"gg fgf fgdfh\"\n",
    "getRandomSentencePrediction(sent,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['story', 'ask_hn', 'show_hn', 'poll'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_2018.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>hacker</th>\n",
       "      <th>news</th>\n",
       "      <th>book</th>\n",
       "      <th>in</th>\n",
       "      <th>2017</th>\n",
       "      <th>beijing</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>best</th>\n",
       "      <th>winter</th>\n",
       "      <th>...</th>\n",
       "      <th>400gb</th>\n",
       "      <th>shareseer</th>\n",
       "      <th>öyster</th>\n",
       "      <th>face-detecting</th>\n",
       "      <th>rainer</th>\n",
       "      <th>rilke</th>\n",
       "      <th>computing.foundation</th>\n",
       "      <th>integer32</th>\n",
       "      <th>nichols</th>\n",
       "      <th>goulding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>7.055676e-07</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_hn</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>2.847721e-06</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show_hn</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>3.487066e-06</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poll</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>1.074576e-05</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 92624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              top    hacker      news      book        in      2017   beijing  \\\n",
       "story    0.000601  0.000493  0.000670  0.000604  0.015977  0.000984  0.000038   \n",
       "ask_hn   0.000214  0.000493  0.000635  0.001421  0.008090  0.000128  0.000009   \n",
       "show_hn  0.000478  0.000701  0.001287  0.000540  0.008017  0.000045  0.000003   \n",
       "poll     0.000011  0.000011  0.000011  0.000032  0.000032  0.000011  0.000011   \n",
       "\n",
       "            enjoy      best    winter  ...         400gb     shareseer  \\\n",
       "story    0.000023  0.000807  0.000069  ...  7.055676e-07  7.055676e-07   \n",
       "ask_hn   0.000060  0.003693  0.000014  ...  2.847721e-06  2.847721e-06   \n",
       "show_hn  0.000010  0.000401  0.000017  ...  3.487066e-06  3.487066e-06   \n",
       "poll     0.000011  0.000032  0.000011  ...  1.074576e-05  1.074576e-05   \n",
       "\n",
       "               öyster  face-detecting        rainer         rilke  \\\n",
       "story    7.055676e-07    7.055676e-07  7.055676e-07  7.055676e-07   \n",
       "ask_hn   2.847721e-06    2.847721e-06  2.847721e-06  2.847721e-06   \n",
       "show_hn  3.487066e-06    3.487066e-06  3.487066e-06  3.487066e-06   \n",
       "poll     1.074576e-05    1.074576e-05  1.074576e-05  1.074576e-05   \n",
       "\n",
       "         computing.foundation     integer32       nichols  goulding  \n",
       "story            7.055676e-07  7.055676e-07  7.055676e-07  0.000001  \n",
       "ask_hn           2.847721e-06  2.847721e-06  2.847721e-06  0.000003  \n",
       "show_hn          3.487066e-06  3.487066e-06  3.487066e-06  0.000003  \n",
       "poll             1.074576e-05  1.074576e-05  1.074576e-05  0.000011  \n",
       "\n",
       "[4 rows x 92624 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_2018.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = getDataframe(2019)\n",
    "testData = addTokenizedColumnofTitle(testData)\n",
    "testData = testData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = generateCondClassProb(testData, model)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['predicted'] = generatePrediction(testData,AllClasses)\n",
    "testData.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResults = comparePredictions(testData,AllClasses)\n",
    "testResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeDataframe(testResults,'result.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = testResults.comparision.value_counts()\n",
    "accuracy = check[True]/(check[True]+check[False])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(testResults['Post Type'], testResults['predicted'])\n",
    "df_confusion['poll'] = 0\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion['precision'] = 0.0\n",
    "df_confusion['recall'] = 0.0\n",
    "#df['F1_score'] = 0.0\n",
    "transpose_matrix = df_confusion.transpose()\n",
    "for i in transpose_matrix.columns:\n",
    "    if np.sum(df_confusion[i])==0:\n",
    "        total = 1\n",
    "    else:\n",
    "        total = np.sum(df_confusion[i])\n",
    "    df_confusion['precision'][i] = df_confusion[i][i]/total\n",
    "    df_confusion['recall'][i] = df_confusion[i][i]/np.sum(transpose_matrix[i])\n",
    "df_confusion['F1_score'] = 2/(1/df_confusion['precision']+1/df_confusion['recall'])\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def model_making(df_train, df_test, labels, delta, file=True, stopwords = None, blocks = None, frequency = None):\n",
    "    df_train['Title'] = df_train['Title'].map(lambda x:x.lower())\n",
    "    df_test['Title'] = df_test['Title'].map(lambda x:x.lower())\n",
    "    if blocks:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if (len(i)>blocks[0] and len(i)<blocks[1])])\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if (len(i)>blocks[0] and len(i)<blocks[1])])\n",
    "    elif stopwords:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if i not in stopwords])\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if i not in stopwords])\n",
    "    else:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:re.split('\\[\\^a-zA-Z\\]',x)[0].split())\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:re.split('\\[\\^a-zA-Z\\]',x)[0].split())\n",
    "    d = {}\n",
    "    totalNumberOfWords = 0\n",
    "    uniqueWords = 0\n",
    "    print(\"Training Started \")\n",
    "    for i in range(len(df_train['tokenized_title'])):\n",
    "        d = input_phrase(df_train['tokenized_title'][i],df_train['Post Type'][i],d,labels)\n",
    "        totalNumberOfWords += len(df_train['tokenized_title'][i])\n",
    "    df_train = pd.DataFrame(d)\n",
    "    if frequency:\n",
    "        df_train[df_train<frequency] = 0\n",
    "    df_train = df_train.transpose()\n",
    "    uniqueWords = len(df_train)\n",
    "    absentWordConditionalProbability = {}\n",
    "    list_classes = []\n",
    "    for className in labels:\n",
    "        wordsPerClass = np.sum(df_train[className])\n",
    "        conditionalClassLabel = 'prob_' + className\n",
    "        df_train[conditionalClassLabel] = df_train[className].map(lambda x: (int(x) + delta)/( wordsPerClass + delta*uniqueWords ))    \n",
    "        absentWordConditionalProbability[conditionalClassLabel] = delta/( wordsPerClass + delta*uniqueWords )\n",
    "        list_classes.append(className)\n",
    "        list_classes.append(conditionalClassLabel)\n",
    "    writeWords = df_train.copy()\n",
    "    words_train = df_train.transpose()\n",
    "    if file:\n",
    "        print(\"Writing the training model to file \")\n",
    "        writeWords.index.name = 'TokenName'\n",
    "        writeWords = writeWords.reset_index()\n",
    "        writeWords = writeWords.sort_values(by ='TokenName')\n",
    "        writeWords = writeWords.reset_index()\n",
    "        cols = ['TokenName'] + list_classes\n",
    "        print(cols)\n",
    "        writeWords = writeWords[cols]\n",
    "        writeWords.index += 1\n",
    "        filename = 'model-2018.txt'\n",
    "        writeWords.to_csv(filename, header = None, index = True, sep = ' ', mode = 'w')\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(' ', '  ') for line in lines]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    print(\"Testing started\")\n",
    "    conditionalProbabilities = words_train.drop(labels)\n",
    "    unique, counts = np.unique(df_2018['Post Type'], return_counts=True)\n",
    "    priorProbabilities = {}\n",
    "    for index in range(len(unique)):\n",
    "        priorProbabilities['prob_' + unique[index]] = counts[index]/np.sum(counts)\n",
    "    for className in list(priorProbabilities.keys()):\n",
    "        df_test[className] = generateScore(df_test['tokenized_title'],className,priorProbabilities,absentWordConditionalProbability,conditionalProbabilities)\n",
    "    columnNamesExchange = {}\n",
    "    for className in labels:\n",
    "        columnNamesExchange['prob_' + className] = className\n",
    "    dfObj = testData[list(priorProbabilities.keys())].copy()\n",
    "    dfObj = dfObj.rename(columns=columnNamesExchange)\n",
    "    dfObj['predicted'] = dfObj.idxmax(axis=1)\n",
    "    dfObj = pd.concat([dfObj, testData[['Title', 'Post Type']]], axis=1)\n",
    "    dfObj['comparision'] = (dfObj['predicted'] == dfObj['Post Type'])\n",
    "    cols = ['Title'] + labels +['Post Type', 'comparision']\n",
    "    #cols = ['Title', 'story', 'ask_hn', 'show_hn', 'poll', 'Post Type', 'comparision']\n",
    "    dfObj = dfObj[cols]\n",
    "    if file:\n",
    "        print(\"Writing a Test file\")\n",
    "        filename = 'result.txt'\n",
    "        dfObj.to_csv(filename, header = None, index = False, sep = ' ', mode = 'w')\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(' ', '  ') for line in lines]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    check = dfObj.comparision.value_counts()\n",
    "    accuracy = check[True]/(check[True]+check[False])\n",
    "    print(\"Training Accuracy :\",round(accuracy,2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_making(df_2018,testData,list(np.unique(df_2018['Post Type'])),0.5,blocks = [2,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
