{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import math\n",
    "\n",
    "from GenerateCorpusDataframe import *\n",
    "from generateWordFrequency import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = getDataframe(2018)\n",
    "df_2018 = addTokenizedColumnofTitle(df_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClasses = list(np.unique(df_2018['Post Type']))\n",
    "AllClasses = ['ask_hn', 'poll', 'show_hn', 'story']\n",
    "delta = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating frequency of each word and given their conditional post type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2018 = getWordFrequencyDataframe(df_2018,AllClasses)\n",
    "totalNumberOfWords = getTotalWordCount(words_2018)\n",
    "words_2018,absentWordConditionalProbability = obtainDataframeWithClassProbabilities(words_2018, AllClasses, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedColumns = ['story', 'prob_story', 'ask_hn', 'prob_ask_hn', 'show_hn', 'prob_show_hn', 'poll', 'prob_poll']\n",
    "filename = 'model-2018.txt'\n",
    "writeModel(words_2018,orderedColumns,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2018.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorProbabilities = {'prob_story':0,'prob_ask_hn':0,'prob_show_hn':0,'prob_poll':0}\n",
    "unique, counts = np.unique(df_2018['Post Type'], return_counts=True)\n",
    "for index in range(len(unique)):\n",
    "    priorProbabilities['prob_' + unique[index]] = counts[index]/np.sum(counts)\n",
    "print(priorProbabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionalProbabilities = words_2018.drop(['story', 'poll', 'show_hn', 'ask_hn'])\n",
    "conditionalProbabilities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConditionalProbability(word,className,absentWordConditionalProbability,conditionalProbabilities):\n",
    "    try:\n",
    "        return conditionalProbabilities[word][className]\n",
    "    except:\n",
    "        return absentWordConditionalProbability[className]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateScore(arrayOfTokenizedTitle,className,priorProbabilities,absentWordConditionalProbability,conditionalProbabilities):\n",
    "    score = np.zeros(len(arrayOfTokenizedTitle)) + math.log10(priorProbabilities[className])\n",
    "    for index in range(len(arrayOfTokenizedTitle)):\n",
    "        wordsList = arrayOfTokenizedTitle[index]\n",
    "        for word in wordsList:\n",
    "            score[index] += math.log10(getConditionalProbability(word,className,absentWordConditionalProbability,conditionalProbabilities))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = data[data[\"year\"]=='2019'][['Title','Post Type']].copy()\n",
    "testData['Title'] = testData['Title'].map(lambda x:x.lower())\n",
    "testData['tokenized_title'] = testData['Title'].map(lambda x:re.split('\\[\\^a-zA-Z\\]',x)[0].split())\n",
    "testData = testData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for className in priorProbabilities.keys():\n",
    "    testData[className] = generateScore(testData['tokenized_title'],className)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNamesExchange = {}\n",
    "for className in ['ask_hn', 'poll', 'show_hn', 'story']:\n",
    "    columnNamesExchange['prob_' + className] = className\n",
    "dfObj = testData[['prob_ask_hn', 'prob_poll', 'prob_show_hn', 'prob_story']].copy()\n",
    "dfObj = dfObj.rename(columns=columnNamesExchange)\n",
    "dfObj['predicted'] = dfObj.idxmax(axis=1)\n",
    "dfObj = pd.concat([dfObj, testData[['Title', 'Post Type']]], axis=1)\n",
    "dfObj['comparision'] = (dfObj['predicted'] == dfObj['Post Type'])\n",
    "cols = ['Title', 'predicted', 'story', 'ask_hn', 'show_hn', 'poll', 'Post Type', 'comparision']\n",
    "dfObj = dfObj[cols]\n",
    "dfObj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result.txt'\n",
    "dfObj.to_csv(filename, header = None, index = False, sep = ' ', mode = 'w')\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line.replace(' ', '  ') for line in lines]\n",
    "with open(filename, 'w') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = dfObj.comparision.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(check).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = check[True]/(check[True]+check[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_making(df_train, df_test, labels, delta, file=True, stopwords = None, blocks = None, frequency = None):\n",
    "    df_train['Title'] = df_train['Title'].map(lambda x:x.lower())\n",
    "    df_test['Title'] = df_test['Title'].map(lambda x:x.lower())\n",
    "    if blocks:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if (len(i)>blocks[0] and len(i)<blocks[1])])\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if (len(i)>blocks[0] and len(i)<blocks[1])])\n",
    "    elif stopwords:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if i not in stopwords])\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:[i for i in re.split('\\[\\^a-zA-Z\\]',x)[0].split() if i not in stopwords])\n",
    "    else:\n",
    "        df_train['tokenized_title'] = df_train['Title'].map(lambda x:re.split('\\[\\^a-zA-Z\\]',x)[0].split())\n",
    "        df_test['tokenized_title'] = df_test['Title'].map(lambda x:re.split('\\[\\^a-zA-Z\\]',x)[0].split())\n",
    "    d = {}\n",
    "    totalNumberOfWords = 0\n",
    "    uniqueWords = 0\n",
    "    print(\"Training Started \")\n",
    "    for i in range(len(df_train['tokenized_title'])):\n",
    "        d = input_phrase(df_train['tokenized_title'][i],df_train['Post Type'][i],d,labels)\n",
    "        totalNumberOfWords += len(df_train['tokenized_title'][i])\n",
    "    df_train = pd.DataFrame(d)\n",
    "    if frequency:\n",
    "        df_train[df_train<frequency] = 0\n",
    "    df_train = df_train.transpose()\n",
    "    uniqueWords = len(df_train)\n",
    "    absentWordConditionalProbability = {}\n",
    "    list_classes = []\n",
    "    for className in labels:\n",
    "        wordsPerClass = np.sum(df_train[className])\n",
    "        conditionalClassLabel = 'prob_' + className\n",
    "        df_train[conditionalClassLabel] = df_train[className].map(lambda x: (int(x) + delta)/( wordsPerClass + delta*uniqueWords ))    \n",
    "        absentWordConditionalProbability[conditionalClassLabel] = delta/( wordsPerClass + delta*uniqueWords )\n",
    "        list_classes.append(className)\n",
    "        list_classes.append(conditionalClassLabel)\n",
    "    writeWords = df_train.copy()\n",
    "    words_train = df_train.transpose()\n",
    "    if file:\n",
    "        print(\"Writing the training model to file \")\n",
    "        writeWords.index.name = 'TokenName'\n",
    "        writeWords = writeWords.reset_index()\n",
    "        writeWords = writeWords.sort_values(by ='TokenName')\n",
    "        writeWords = writeWords.reset_index()\n",
    "        cols = ['TokenName'] + list_classes\n",
    "        print(cols)\n",
    "        writeWords = writeWords[cols]\n",
    "        writeWords.index += 1\n",
    "        filename = 'model-2018.txt'\n",
    "        writeWords.to_csv(filename, header = None, index = True, sep = ' ', mode = 'w')\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(' ', '  ') for line in lines]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    print(\"Testing started\")\n",
    "    conditionalProbabilities = words_train.drop(labels)\n",
    "    unique, counts = np.unique(df_2018['Post Type'], return_counts=True)\n",
    "    priorProbabilities = {}\n",
    "    for index in range(len(unique)):\n",
    "        priorProbabilities['prob_' + unique[index]] = counts[index]/np.sum(counts)\n",
    "    for className in list(priorProbabilities.keys()):\n",
    "        df_test[className] = generateScore(df_test['tokenized_title'],className,priorProbabilities,absentWordConditionalProbability,conditionalProbabilities)\n",
    "    columnNamesExchange = {}\n",
    "    for className in labels:\n",
    "        columnNamesExchange['prob_' + className] = className\n",
    "    dfObj = testData[list(priorProbabilities.keys())].copy()\n",
    "    dfObj = dfObj.rename(columns=columnNamesExchange)\n",
    "    dfObj['predicted'] = dfObj.idxmax(axis=1)\n",
    "    dfObj = pd.concat([dfObj, testData[['Title', 'Post Type']]], axis=1)\n",
    "    dfObj['comparision'] = (dfObj['predicted'] == dfObj['Post Type'])\n",
    "    cols = ['Title'] + labels +['Post Type', 'comparision']\n",
    "    #cols = ['Title', 'story', 'ask_hn', 'show_hn', 'poll', 'Post Type', 'comparision']\n",
    "    dfObj = dfObj[cols]\n",
    "    if file:\n",
    "        print(\"Writing a Test file\")\n",
    "        filename = 'result.txt'\n",
    "        dfObj.to_csv(filename, header = None, index = False, sep = ' ', mode = 'w')\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(' ', '  ') for line in lines]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    check = dfObj.comparision.value_counts()\n",
    "    accuracy = check[True]/(check[True]+check[False])\n",
    "    print(\"Training Accuracy :\",round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_making(df_2018,testData,list(np.unique(df_2018['Post Type'])),0.5,blocks = [2,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
