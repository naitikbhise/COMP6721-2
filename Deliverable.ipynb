{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Project #2 Hacker News Dataset Analysis\n",
    "# Written by Naitik Bhise (40106507) and Paras Kapoor (40114178)\n",
    "# For COMP 6721 Section FI â€“ Fall 2019\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from generateWordFrequency import *\n",
    "from naiveBayes import *\n",
    "from fileWriteFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPlot(X,Y,xlabel,ylabel,title):\n",
    "    plt.figure()\n",
    "    plt.scatter(X, Y, marker='*',\n",
    "           s=10, facecolor='blue')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON DATA LOADING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteList(unwanted_tokens,'remove_word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClasses = ['story', 'ask_hn', 'show_hn', 'poll']\n",
    "appendClassPrefix = 'prob_'\n",
    "\n",
    "unfilteredTrainData = getDataframe(2018,\"hn2018_2019.csv\")\n",
    "unfilteredTrainData = addTokenizedColumnofTitle(unfilteredTrainData)\n",
    "\n",
    "unfilteredTestData = getDataframe(2019,\"hn2018_2019.csv\")\n",
    "unfilteredTestData = addTokenizedColumnofTitle(unfilteredTestData)\n",
    "unfilteredTestData = unfilteredTestData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel(trainData, delta, filename = 'temp-model.txt'):\n",
    "    priorProbabilities = getPriorProbabilities(trainData)\n",
    "    trainWords = getWordFrequencyDataframe(trainData,AllClasses)\n",
    "    trainWords = obtainDataframeWithClassProbabilities(trainWords, AllClasses, delta, appendClassPrefix)\n",
    "    writeModel(trainWords,filename,AllClasses,appendClassPrefix)\n",
    "    trainWords = renameModelRows(trainWords, AllClasses, appendClassPrefix)\n",
    "    model = [trainWords, priorProbabilities]\n",
    "    return model\n",
    "\n",
    "def showAccuracies(y_true,y_pred, display = False):\n",
    "    cf_m = confusion_matrix(y_true, y_pred, labels=AllClasses)\n",
    "    df = pd.DataFrame(cf_m,columns=['pred_' + className for className in AllClasses],\n",
    "                  index=['true_' + className for className in AllClasses])\n",
    "    df_ = pd.DataFrame(np.zeros((len(AllClasses),3)),\n",
    "                       index=AllClasses,columns=['precision','recall','F1score'])\n",
    "\n",
    "    for className in AllClasses:\n",
    "        if df.sum(axis=0)['pred_' + className] == 0:\n",
    "            precision = 0\n",
    "        else:    \n",
    "            precision = df['pred_' + className]['true_' + className]/df.sum(axis=0)['pred_' + className]\n",
    "        if df.sum(axis=1)['true_' + className] == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = df['pred_' + className]['true_' + className]/df.sum(axis=1)['true_' + className]\n",
    "        df_['recall'][className] = recall\n",
    "        df_['precision'][className] = precision\n",
    "        if precision == 0 or recall == 0:\n",
    "            df_['F1score'][className] = 0\n",
    "        else:\n",
    "            df_['F1score'][className] = 2*precision*recall/(precision + recall)\n",
    "    if display:\n",
    "        print(df)\n",
    "        #print(df.to_latex(index=True))\n",
    "        print(df_)\n",
    "        #print(df_.to_latex(index=True))\n",
    "\n",
    "def testModel(testData, model, filename = 'temp-results.txt', display = False):\n",
    "    testData = generateCondClassProb(testData, model)\n",
    "    testData['predicted'] = generatePrediction(testData,AllClasses)\n",
    "    testResults = comparePredictions(testData,AllClasses)\n",
    "    writeDataframe(testResults,filename)\n",
    "    showAccuracies(testResults['Post Type'],testResults['predicted'],display)\n",
    "    check = testResults.comparision.value_counts()\n",
    "    accuracy = check[True]/(check[True]+check[False])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1:  Extract the data and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = unfilteredTrainData.copy()\n",
    "model = generateModel(trainData, 0.5, 'model-2018.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Use ML Classifier to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = unfilteredTestData.copy()\n",
    "accuracy = testModel(testData, model, 'baseline-result.txt', True)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Experiments with the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP 3.1:  Stop-word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Stopwords.txt'\n",
    "with open (filename, \"r\") as myfile:\n",
    "    data = myfile.readlines()\n",
    "filteredWordList = [word[0:-1] for word in data if len(word[0:-1])]\n",
    "trainData = filterTokensByWordList(unfilteredTrainData.copy(),filteredWordList)\n",
    "testData = filterTokensByWordList(unfilteredTestData.copy(),filteredWordList)\n",
    "model = generateModel(trainData, 0.5, 'stopword-model.txt')\n",
    "accuracy = testModel(testData, model, 'stopword-result.txt', True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP 3.2:   Word Length Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = filterTokensByWordLength(unfilteredTrainData.copy())\n",
    "testData = filterTokensByWordLength(unfilteredTestData.copy())\n",
    "model = generateModel(trainData, 0.5, 'wordlength-model.txt')\n",
    "accuracy = testModel(testData, model, 'wordlength-result.txt', True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP 3.3: Infrequent Word Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 COUNT BASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "VocabularySize = []\n",
    "for count in [1,5,10,15,20]:\n",
    "    trainWords = getWordFrequencyDataframe(unfilteredTrainData,AllClasses)\n",
    "    filteredWordList = getWordListBasedOnCount(trainWords,maxCount = count)    \n",
    "    trainData = filterTokensByWordList(unfilteredTrainData.copy(),filteredWordList)\n",
    "    testData = filterTokensByWordList(unfilteredTestData.copy(),filteredWordList)\n",
    "    model = generateModel(trainData, 0.5)\n",
    "    accuracy = testModel(testData, model)\n",
    "    vocabSize = len(model[0].columns)    \n",
    "    accuracies.append(accuracy)\n",
    "    VocabularySize.append(vocabSize)\n",
    "    print(count,accuracy,vocabSize)\n",
    "drawPlot(VocabularySize,accuracies,'Vocubalary Size','Test Accuracy','Filtering based on WordCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 TOP X % FREQUENT WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "VocabularySize = []\n",
    "for percent in [5,10,15,20,25]:\n",
    "    trainWords = getWordFrequencyDataframe(unfilteredTrainData,AllClasses)\n",
    "    filteredWordList = getWordListBasedOnPercent(trainWords,Percent = percent)\n",
    "    trainData = filterTokensByWordList(unfilteredTrainData.copy(),filteredWordList)\n",
    "    testData = filterTokensByWordList(unfilteredTestData.copy(),filteredWordList)\n",
    "    model = generateModel(trainData, 0.5)\n",
    "    accuracy = testModel(testData, model)\n",
    "    vocabSize = len(model[0].columns)    \n",
    "    accuracies.append(accuracy)\n",
    "    VocabularySize.append(vocabSize)\n",
    "    print(percent,accuracy,vocabSize)\n",
    "drawPlot(VocabularySize,accuracies,'Vocubalary Size','Test Accuracy','Filtering based on Top x% Frequent Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP 3.3: Delta Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "Deltas = 0.1*np.arange(0,11)\n",
    "for delta in Deltas:\n",
    "    trainData = unfilteredTrainData.copy()\n",
    "    testData = unfilteredTestData.copy()    \n",
    "    model = generateModel(trainData, delta)\n",
    "    accuracy = testModel(testData, model)    \n",
    "    accuracies.append(accuracy)\n",
    "drawPlot(Deltas,accuracies,'Delta Values','Test Accuracy','Smoothening Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
