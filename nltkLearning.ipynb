{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/fracton/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/fracton/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'86\", '[']\n",
      "[(\"'86\", 'CD'), ('[', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"'86  [\")\n",
    "print(text)\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"'86\".isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer NNP n Computer\n",
      "Science NNP n Science\n",
      "is VBZ v be\n",
      "a DT None a\n",
      "better JJR a good\n",
      "but CC None but\n",
      "a DT None a\n",
      "subject NN n subject\n"
     ]
    }
   ],
   "source": [
    "for word,pos in nltk.pos_tag(text):\n",
    "    tag = penn_to_wn(pos)\n",
    "    if tag is None:\n",
    "        lemmatizedWord = word\n",
    "    else:\n",
    "        lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "    print(word,pos,tag,lemmatizedWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_split(sentence):\n",
    "    text = nltk.word_tokenize(sentence)\n",
    "    pos_text = nltk.pos_tag(text)\n",
    "    new_text = []\n",
    "    grab = False\n",
    "    lemmatizedWord = None\n",
    "    for word,pos in pos_text:\n",
    "        print(word,pos)\n",
    "        tag = penn_to_wn(pos)\n",
    "        \n",
    "        if pos == 'NNP' and grab == True:\n",
    "            grab = False\n",
    "            #print(word)\n",
    "            if word.isalpha():\n",
    "                lemmatizedWord += \" \" + wordnet_lemmatizer.lemmatize(word,tag)\n",
    "                new_text.append(lemmatizedWord.lower())\n",
    "            lemmatizedWord = None\n",
    "        elif pos == 'NNP' and grab == False:\n",
    "            if word.isalpha():\n",
    "                lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "                grab = True\n",
    "            #print(grab)\n",
    "        elif pos != 'NNP':\n",
    "            if lemmatizedWord:\n",
    "                new_text.append(lemmatizedWord.lower())\n",
    "                grab = False\n",
    "            if tag is None:\n",
    "                lemmatizedWord = word\n",
    "            else:\n",
    "                lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            if lemmatizedWord or pos=='JJ': \n",
    "                new_text.append(lemmatizedWord.lower())\n",
    "            lemmatizedWord = None\n",
    "            grab = False\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask NNP\n",
      "HN NNP\n",
      ": :\n",
      "Any DT\n",
      "domain NN\n",
      "name NN\n",
      "registrars VBZ\n",
      "that WDT\n",
      "do VBP\n",
      "n't RB\n",
      "require VB\n",
      "JavaScript NNP\n",
      "? .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ask hn',\n",
       " ':',\n",
       " 'any',\n",
       " 'domain',\n",
       " 'name',\n",
       " 'registrars',\n",
       " 'that',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'require',\n",
       " 'javascript',\n",
       " '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split(\"Ask HN: Any domain name registrars that don't require JavaScript?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruby NN\n",
      "3x3 CD\n",
      "– NNP\n",
      "ruby NN\n",
      "3 CD\n",
      "will MD\n",
      "be VB\n",
      "3 CD\n",
      "times NNS\n",
      "faster RBR\n",
      "– VBP\n",
      "what WP\n",
      "'s VBZ\n",
      "news NN\n",
      "? .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ruby',\n",
       " '3x3',\n",
       " 'ruby',\n",
       " '3',\n",
       " 'will',\n",
       " 'be',\n",
       " '3',\n",
       " 'time',\n",
       " 'faster',\n",
       " '–',\n",
       " 'what',\n",
       " \"'s\",\n",
       " 'news',\n",
       " '?']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split(\"Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – What's News?\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Computer Science\"\n",
    "string_2 = \"–\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_2.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_2.isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_split(sentence):\n",
    "    text = nltk.word_tokenize(sentence)\n",
    "    pos_text = nltk.pos_tag(text)\n",
    "    new_text = []\n",
    "    grab = False\n",
    "    lemmatizedWord = None\n",
    "    for word,pos in pos_text:\n",
    "        #print(word)\n",
    "        #print(pos)\n",
    "        tag = penn_to_wn(pos)\n",
    "        if pos == 'NNP' and grab == True:\n",
    "            grab = False\n",
    "            #print(word)\n",
    "            lemmatizedWord += \" \" + wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            new_text.append(lemmatizedWord.lower())\n",
    "            lemmatizedWord = None\n",
    "        elif pos == 'NNP' and grab == False:\n",
    "            lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            grab = True\n",
    "            #print(grab)\n",
    "        elif pos != 'NNP':\n",
    "            if lemmatizedWord:\n",
    "                if lemmatizedWord.isalpha():\n",
    "                    new_text.append(lemmatizedWord.lower())\n",
    "            if tag is None:\n",
    "                lemmatizedWord = word\n",
    "            else:\n",
    "                lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            if lemmatizedWord.isalpha() or pos=='JJ':\n",
    "                if word.isalpha():\n",
    "                    new_text.append(lemmatizedWord.lower())\n",
    "            lemmatizedWord = None\n",
    "            grab = False\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ruby', '3x3', '–', 'ruby', '3', 'will', 'be', '3', 'times', 'faster', 'tesla-based', '–', 'what', \"'s\", 'news', '?']\n",
      "[('ruby', 'NN'), ('3x3', 'CD'), ('–', 'NNP'), ('ruby', 'NN'), ('3', 'CD'), ('will', 'MD'), ('be', 'VB'), ('3', 'CD'), ('times', 'NNS'), ('faster', 'RBR'), ('tesla-based', 'JJ'), ('–', 'NNP'), ('what', 'WP'), (\"'s\", 'VBZ'), ('news', 'NN'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Ruby 3x3 – Ruby 3 Will Be 3 Times Faster Tesla-based – What's News?\".lower())\n",
    "print(text)\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
