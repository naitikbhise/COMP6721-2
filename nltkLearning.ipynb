{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/fracton/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/fracton/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer', 'Science', 'is', 'a', 'better', 'but', 'a', 'subject']\n",
      "[('Computer', 'NNP'), ('Science', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('better', 'JJR'), ('but', 'CC'), ('a', 'DT'), ('subject', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Computer Science is a better but a  subject\")\n",
    "print(text)\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer NNP n Computer\n",
      "Science NNP n Science\n",
      "is VBZ v be\n",
      "a DT None a\n",
      "better JJR a good\n",
      "but CC None but\n",
      "a DT None a\n",
      "subject NN n subject\n"
     ]
    }
   ],
   "source": [
    "for word,pos in nltk.pos_tag(text):\n",
    "    tag = penn_to_wn(pos)\n",
    "    if tag is None:\n",
    "        lemmatizedWord = word\n",
    "    else:\n",
    "        lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "    print(word,pos,tag,lemmatizedWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_split(sentence):\n",
    "    text = [x for x in nltk.word_tokenize(sentence) if x.isalpha()]\n",
    "    pos_text = nltk.pos_tag(text)\n",
    "    new_text = []\n",
    "    grab = False\n",
    "    for word,pos in pos_text:\n",
    "        #print(word)\n",
    "        #print(pos)\n",
    "        tag = penn_to_wn(pos)\n",
    "        if pos == 'NNP' and grab == True:\n",
    "            grab = False\n",
    "            #print(word)\n",
    "            lemmatizedWord += \" \" + wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            new_text.append(lemmatizedWord)\n",
    "            lemmatizedWord = None\n",
    "        elif pos == 'NNP' and grab == False:\n",
    "            lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            grab = True\n",
    "            #print(grab)\n",
    "        elif pos != 'NNP':\n",
    "            if lemmatizedWord:\n",
    "                new_text.append(lemmatizedWord)\n",
    "            if tag is None:\n",
    "                lemmatizedWord = word\n",
    "            else:\n",
    "                lemmatizedWord = wordnet_lemmatizer.lemmatize(word,tag)\n",
    "            new_text.append(lemmatizedWord)\n",
    "            lemmatizedWord = None\n",
    "            grab = False\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer Science',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'subject',\n",
       " 'consisting',\n",
       " 'of',\n",
       " 'stream',\n",
       " 'like',\n",
       " 'Information Technology',\n",
       " 'Networks Telecommunications',\n",
       " 'and',\n",
       " 'Data Science']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split(\"Computer Science is a better subject consisting of streams like Information Technology, Networks, Telecommunications and Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'penn_to_wn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-85238b1d91da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computer Science is a better but a daunting subject\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5ef01161c63e>\u001b[0m in \u001b[0;36msentence_split\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(pos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenn_to_wn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NNP'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgrab\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mgrab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'penn_to_wn' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_split(\"Computer Science is a better but a daunting subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Computet\"\n",
    "string_2 = \"18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_2.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_2.isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
